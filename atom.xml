<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A.bin&#39;s Blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-04-21T14:38:38.333Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>A.bin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>爬虫与面向对象爬虫</title>
    <link href="http://example.com/2021/04/21/%E7%88%AC%E8%99%AB/"/>
    <id>http://example.com/2021/04/21/%E7%88%AC%E8%99%AB/</id>
    <published>2021-04-21T10:50:34.000Z</published>
    <updated>2021-04-21T14:38:38.333Z</updated>
    
    <content type="html"><![CDATA[<h1 id="普通面向对象（爬取burst-shopify-com下的图片）"><a href="#普通面向对象（爬取burst-shopify-com下的图片）" class="headerlink" title="普通面向对象（爬取burst.shopify.com下的图片）"></a>普通面向对象（爬取burst.shopify.com下的图片）</h1><h3 id="总体思想"><a href="#总体思想" class="headerlink" title="总体思想:"></a><strong>总体思想</strong>:</h3><p>​    第一步：观察网页构造，为写代码做准备，检查是否有反爬技术</p><p>​    第二布：检查所要下载的图片，观察格式，并且构造正则表达式</p><p>​    第三步：过滤重复的图片</p><p>​    第四步：保存图片，并作相关优化</p><h3 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a><strong>代码如下：</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import requests</span><br><span class="line">x&#x3D;0</span><br><span class="line">j&#x3D;1</span><br><span class="line">count&#x3D;0</span><br><span class="line">print(&quot;&#39;animals&#39; &#39;city&#39; &#39;home&#39; &#39;seasons&#39; &#39;education&#39; &#39;landscape&#39; &#39;family&#39; \n &quot;</span><br><span class="line">      &quot;&#39;love&#39; &#39;around the world&#39; &#39;arts&#39; &#39;technology&#39; &#39;outdoor&#39; &#39;backgrounds&#39; \n &quot;</span><br><span class="line">      &quot;&#39;fashion&#39; &#39;beauty&#39; &#39;people&#39; &#39;transportation&#39; &#39;business&#39; \n &quot;</span><br><span class="line">      &quot;&#39;fitness&#39; &#39;travel&#39; &#39;flowers&#39; &#39;work&#39; &#39;food&#39; &#39;holidays&#39; &#39;celebrate&#39;&quot;)</span><br><span class="line"></span><br><span class="line">    #&#123;设置头，反爬&#125;</span><br><span class="line">headers&#x3D;&#123;</span><br><span class="line">&quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;89.0.4389.128 Safari&#x2F;537.36&quot;</span><br><span class="line">&#125;</span><br><span class="line">key &#x3D; input(&#39;请从上面挑选出要下载的图片类型：&#39;)</span><br><span class="line">num &#x3D; int(input(&#39;请输入一共要下载的页数：&#39;))</span><br><span class="line"></span><br><span class="line">    # &#123;请求url与编写正则表达式&#125;</span><br><span class="line">if num &gt;&#x3D; 1:</span><br><span class="line">    while j &lt;&#x3D; num:</span><br><span class="line">        url &#x3D; &#39;https:&#x2F;&#x2F;burst.shopify.com&#x2F;&#39; + key + &#39;?page&#x3D;&#39; + str(j)</span><br><span class="line">        resp&#x3D;requests.get(url,headers&#x3D;headers)</span><br><span class="line">        html&#x3D;resp.text</span><br><span class="line">        urls&#x3D;re.findall(&quot;https:&#x2F;&#x2F;burst.*?jpg&quot;, html)</span><br><span class="line">        lst&#x3D;[]</span><br><span class="line"></span><br><span class="line">    # &#123;当第二页刷新时有和第一页相同的图片,所以以下为去重代码&#125;</span><br><span class="line">        if j &#x3D;&#x3D; 1 :</span><br><span class="line">            for i in urls:   #遍历jpg</span><br><span class="line">                if i not in lst:</span><br><span class="line">                    lst.append(i)</span><br><span class="line">        elif j&gt;1:</span><br><span class="line">            for i in urls:</span><br><span class="line">                if i not in lst2 and i not in lst:  #判断新urls里的jpg是否与lst列表里的相同</span><br><span class="line">                    lst.append(i)</span><br><span class="line"></span><br><span class="line">    # &#123;保存图片&#125;</span><br><span class="line">        for url in lst:</span><br><span class="line">            file_name &#x3D;&quot;E:&#x2F;大学&#x2F;python爬虫&#x2F;&quot;+ str(j) + &#39;.&#39; + str(x) + &quot;.jpg&quot;   #设置文件名</span><br><span class="line">            resp &#x3D; requests.get(url, headers&#x3D;headers)</span><br><span class="line">            with open(file_name, &#39;wb&#39;) as f:    #以二进制的方式写进</span><br><span class="line">                f.write(resp.content)</span><br><span class="line">            print(&quot;正在下载第&#123;0&#125;页第&#123;1&#125;张图片&quot;.format(j,x))</span><br><span class="line">            x&#x3D;x+1</span><br><span class="line"></span><br><span class="line">    # &#123;计数部分&#125;</span><br><span class="line">            if x&#x3D;&#x3D;len(lst):</span><br><span class="line">                if j !&#x3D; 1:</span><br><span class="line">                    pass        # 这一部分if指lst2&#x3D;lst只执行一次，</span><br><span class="line">                else:</span><br><span class="line">                    lst2 &#x3D; lst</span><br><span class="line">                x&#x3D;0</span><br><span class="line">                j&#x3D;j+1</span><br><span class="line">                count +&#x3D; len(lst)</span><br><span class="line">print(&quot;下载完成！共下载&#123;0&#125;张图片&quot;.format(count))</span><br></pre></td></tr></table></figure><h1 id="面向对象爬虫（爬取burst-shopify-com下的图片）"><a href="#面向对象爬虫（爬取burst-shopify-com下的图片）" class="headerlink" title="面向对象爬虫（爬取burst.shopify.com下的图片）"></a>面向对象爬虫（爬取burst.shopify.com下的图片）</h1><p>​    所谓面向对象也就是通过创建一个类，再创建若干个对象，然后再统一调动</p><h3 id="代码如下：-1"><a href="#代码如下：-1" class="headerlink" title="代码如下："></a>代码如下：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">from urllib.request import urlretrieve</span><br><span class="line">class Tupian(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.base_url&#x3D;&quot;https:&#x2F;&#x2F;burst.shopify.com&#x2F;love?page&#x3D;&#123;&#125;&quot;</span><br><span class="line">        self.header&#x3D;&#123;&quot;user-agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;89.0.4389.128 Safari&#x2F;537.36&quot;</span><br><span class="line">                     &#125;</span><br><span class="line">    def Geturl(self):</span><br><span class="line">        all_url &#x3D; []</span><br><span class="line">        for str in range(1,3):</span><br><span class="line">            all_url.append(self.base_url.format(str))</span><br><span class="line">        return all_url</span><br><span class="line"></span><br><span class="line">    def Respons(self,all_url):</span><br><span class="line">        text_list &#x3D; []</span><br><span class="line">        for url in all_url:</span><br><span class="line">            r &#x3D; requests.get(url, headers&#x3D;self.header)</span><br><span class="line">            text_list.append(r.text)</span><br><span class="line">        return text_list</span><br><span class="line"></span><br><span class="line">    def clear(self, respons):</span><br><span class="line">        for i in respons:</span><br><span class="line">            qqq &#x3D; &quot;https:&#x2F;&#x2F;burst.*?jpg&quot;</span><br><span class="line">            pi &#x3D; re.findall(qqq, i)</span><br><span class="line">            lst&#x3D;[]</span><br><span class="line">            for j in pi:   #遍历jpg</span><br><span class="line">                if j not in lst:</span><br><span class="line">                    lst.append(j)</span><br><span class="line">            return lst</span><br><span class="line"></span><br><span class="line">    def save(self, url_list):</span><br><span class="line">        x&#x3D;0</span><br><span class="line">        for url in url_list:</span><br><span class="line">            x &#x3D; x + 1</span><br><span class="line">            print(url)</span><br><span class="line">            file_name &#x3D; &quot;E:&#x2F;大学&#x2F;python面向对象爬虫&#x2F;&quot;+ str(x) + &quot;.jpg&quot;</span><br><span class="line">            urlretrieve(url, file_name)</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        titile_url &#x3D; self.Geturl()</span><br><span class="line">        respons &#x3D; self.Respons(titile_url)</span><br><span class="line">        picture &#x3D; self.clear(respons)</span><br><span class="line">        print(picture)</span><br><span class="line">        download &#x3D; self.save(picture)</span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    tupian &#x3D; Tupian()</span><br><span class="line">    tupian.run()</span><br></pre></td></tr></table></figure><h1 id="爬虫笔记："><a href="#爬虫笔记：" class="headerlink" title="爬虫笔记："></a>爬虫笔记：</h1><h2 id="抓取网页源代码"><a href="#抓取网页源代码" class="headerlink" title="抓取网页源代码"></a>抓取网页源代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen</span><br><span class="line">url &#x3D;&quot;http:&#x2F;&#x2F;www.baidu.com&quot;</span><br><span class="line">resp &#x3D; urlopen(url)</span><br><span class="line">with open(&quot;my baidu.html&quot;,&quot;w&quot;,encoding&#x3D;&quot;utf-8&quot;) as f:  #把读取的数据放入一个html文件里</span><br><span class="line">    f.write(resp.read().decode(&quot;utf-8&quot;))#读取到页面源代码</span><br></pre></td></tr></table></figure><h2 id="Web请求过程剖析"><a href="#Web请求过程剖析" class="headerlink" title="Web请求过程剖析"></a>Web请求过程剖析</h2><ul><li>服务器渲染：在服务器那边直接把数据和html整合在一起，统一返回给浏览器</li></ul><ul><li> 客户端渲染：第一次请求只要一个html护甲，第二次请求拿到数据，进行数据展示，也就是在页面源    代码中看不到数据。（因为超链接，已经进入下一个网页）</li></ul><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p><img src="https://www.hualigs.cn/image/6080384636f52.jpg" alt="正则表达式"></p><p>![](C:\Users\Pro 13\blog\themes\butterfly\source\img\正则表达式.png)</p><p>​    <strong>.*?   尽可能少的匹配中间字符</strong></p><h2 id="re模块"><a href="#re模块" class="headerlink" title="re模块"></a>re模块</h2><ul><li><p>findall：匹配字符串中所有的符合正则的内容列表，效率不高）</p></li><li><p>finditer：匹配字符串中所有的内容【返回的是迭代器】，从迭代器中拿到内容需要.group()</p><p>​            <code>it = re.finditer(&quot;&quot;,&quot;&quot;)</code></p><p>​            <code>for i in it :</code></p><p>​        <code>print(i,group())</code></p></li><li><p>search：找到一个结果就返回，返回的结果是match对象，拿数据需要.group()</p></li><li><p>预加载正则表达式</p><p>​        <code>obj = re.compile(&quot;\d&quot;)</code></p><p>​        <code>xx=obj.finditer/search()</code></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;普通面向对象（爬取burst-shopify-com下的图片）&quot;&gt;&lt;a href=&quot;#普通面向对象（爬取burst-shopify-com下的图片）&quot; class=&quot;headerlink&quot; title=&quot;普通面向对象（爬取burst.shopify.com下的图片</summary>
      
    
    
    
    <category term="-Python -数据挖掘" scheme="http://example.com/categories/Python-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
    <category term="-普通爬图片 -面向对象爬图片" scheme="http://example.com/tags/%E6%99%AE%E9%80%9A%E7%88%AC%E5%9B%BE%E7%89%87-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%88%AC%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2021/04/20/hello-world/"/>
    <id>http://example.com/2021/04/20/hello-world/</id>
    <published>2021-04-20T10:28:31.440Z</published>
    <updated>2021-04-20T10:28:31.440Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
